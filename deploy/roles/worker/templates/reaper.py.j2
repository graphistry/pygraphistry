#!/usr/bin/env python

from pymongo import MongoClient, ASCENDING, errors
from datetime import datetime, timedelta
import subprocess
import socket
import time
import os
import signal
import urllib2
import requests
from requests.auth import HTTPBasicAuth

import logging
import sys

logger = logging.getLogger()
logger.setLevel(logging.WARNING)

ch = logging.StreamHandler(sys.stdout)
ch.setLevel(logging.INFO)
formatter = logging.Formatter('%(asctime)s :: %(message)s')
ch.setFormatter(formatter)
logger.addHandler(ch)

auth = HTTPBasicAuth('abe@graphistry.com', 'api.fc39b94e8f-3713')
ip = urllib2.urlopen("http://169.254.169.254/latest/meta-data/public-ipv4").read()

def convert(gpu_memory_used):
    if 'GiB' in gpu_memory_used:
        gpu_memory_used = int(gpu_memory_used.replace('GiB','')) * 1024 * 1024 * 1024

    elif 'MiB' in gpu_memory_used:
        gpu_memory_used = int(gpu_memory_used.replace('MiB','')) * 1024 * 1024

    elif 'KiB' in gpu_memory_used:
        gpu_memory_used = int(gpu_memory_used.replace('KiB','')) * 1024

    return gpu_memory_used

def monitor(db):
    """
    This monitors GPU usage using nvidia-smi and updates it in the gpu_monitor
    table (for overall usage) and the node_monitor table (for individual usage)
    """
    global ip

    # Get GPU free memory from nvidia-smi
    p = subprocess.Popen(["nvidia-smi",
                        "--query-gpu=memory.free",
                        "--format=csv,noheader"], stdout=subprocess.PIPE)
    gpu_data = p.communicate()[0]
    gpu_memory_free = convert(gpu_data)
    db['gpu_monitor'].update({'ip': ip}, {'$set':
        {
            'gpu_memory_free': gpu_memory_free,
            'updated': datetime.utcnow()
        }}, True)
    logger.info('gpu_memory_free %s' % gpu_memory_free)

    # Post GPU data to Boundary
    data = '{"source": "%s", "metric": "GPU_FREE", "measure": %s, "timestamp": %s}' % (ip, gpu_memory_free, int(time.time()))
    headers = {'content-type': 'application/json'}
    r = requests.post(url="https://premium-api.boundary.com/v1/measurements", data=data, auth=auth, headers=headers)
    # logger.info(data)
    # logger.info("boundary status: %s" % str(r.json()))

    # Get per-process data from nvidia-smi
    p = subprocess.Popen(["nvidia-smi",
                        "--query-compute-apps=used_gpu_memory,pid",
                        "--format=csv,noheader"], stdout=subprocess.PIPE)
    process_data = p.communicate()[0].split('\n')

    # Update db for each process talking to the GPU
    # Todo: set this up with Graphite
    collection = db['node_monitor']
    for process in process_data:
        logger.info("Process GPU date: %s" % str(process))
        process = process.replace(' ', '').split(',')
        if process == ['']:
            continue

        gpu_memory_used = convert(process[0])

        doc = {
                'ip': ip,
                'pid': process[1]
               }

        collection.update(doc, {'$set': {'gpu_memory_used' : gpu_memory_used } })

def reap(db):
    """
    This reaps all dead processes by checking the node_monitor table for
    outdated rows. The rows should be updated every three seconds by each node
    process itself. This also finds all active processes with users and
    updates Boundary.
    """
    global ip

    # Select all checkins older than 30 seconds
    collection = db['node_monitor']
    old = collection.find({"ip": ip, "updated": {"$lt": datetime.now() - timedelta(seconds=30)}})
    for doc in old:
        pid = doc['pid']
        port = doc['port']
        collection.remove({"_id": doc['_id']})
        logger.info("killing {0}".format(pid))
        try:
            os.kill(pid, signal.SIGKILL)
        except:
            pass

    # Update Boundary
    active = collection.find({"ip": ip, "active": True})
    active_users = 0
    for doc in active:
      active_users += 1
    data = '{"source": "%s", "metric": "ACTIVE_USERS", "measure": %s, "timestamp": %s}' % (ip, active_users, int(time.time()))
    headers = {'content-type': 'application/json'}
    r = requests.post(url="https://premium-api.boundary.com/v1/measurements", data=data, auth=auth, headers=headers)
    # logger.info(data)
    # logger.info("boundary status: %s" % str(r.json()))

    # Update Boundary
    inactive = collection.find({"ip": ip, "active": False})
    inactive_workers = 0
    for doc in inactive:
      inactive_workers += 1
    data = '{"source": "%s", "metric": "INACTIVE_WORKERS", "measure": %s, "timestamp": %s}' % (ip, inactive_workers, int(time.time()))
    headers = {'content-type': 'application/json'}
    r = requests.post(url="https://premium-api.boundary.com/v1/measurements", data=data, auth=auth, headers=headers)
    # logger.info(data)
    # logger.info("boundary status: %s " % str(r.json()))

if __name__=="__main__":
    DATABASE = '{{ mongodb_dbname }}'
    MONGO_SERVER = 'mongodb://graphistry:graphtheplanet@lighthouse.2.mongolayer.com:10048,lighthouse.3.mongolayer.com:10048/{{ mongodb_dbname }}';

    # Connect to central db
    url = MONGO_SERVER
    conn = MongoClient(url)
    db = conn[DATABASE]
    while 1:
        try:
            db.node_monitor.ensure_index( [("port", ASCENDING), ("ip", ASCENDING), ("pid", ASCENDING)], unique=True )
            monitor(db)
            reap(db)
        except errors.ConnectionFailure:
          conn = MongoClient(url)
          db = conn[DATABASE]
        except Exception as e:
            print e

        time.sleep(10)
