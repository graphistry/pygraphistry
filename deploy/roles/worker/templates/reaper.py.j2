#!/usr/bin/env python

from pymongo import MongoClient, ASCENDING, errors
from datetime import datetime, timedelta
import subprocess
import socket
import time
import os
import random
import signal
import urllib2
import requests
from requests.auth import HTTPBasicAuth

import logging
import sys

loggerParent = logging.getLogger()
loggerParent.setLevel(logging.ERROR)

# Quiet down request's log output
requests_log = logging.getLogger("requests.packages.urllib3")
requests_log.setLevel(logging.ERROR)
requests_log.propagate = False

# Our own logging object
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)
logger.propagate = True

ch = logging.StreamHandler(sys.stdout)
ch.setLevel(logging.INFO)
formatter = logging.Formatter('%(asctime)s :: %(message)s')
ch.setFormatter(formatter)
logger.addHandler(ch)

# The number of seconds without a ping before a worker process is considered a zombie
WORKER_TIMEOUT = 30

auth = HTTPBasicAuth('{{ boundary_username }}', '{{ boundary_password }}')
ip = urllib2.urlopen("http://169.254.169.254/latest/meta-data/public-ipv4").read()
HOSTNAME = socket.getfqdn()

DATABASE = '{{ mongodb_dbname }}'
MONGO_SERVER = '{{ mongodb_url }}'


def connect_mongo():
    """ Connects to the MongoDB database and returns a dictionary with the database object,
    gpu_monitor collection, and node_monitor collection."""
    logger.info("Connecting to MongoDB at URL '{url}' and using the database named {db}".format(url=MONGO_SERVER, db=DATABASE))
    client = MongoClient(MONGO_SERVER)
    db = client[DATABASE]
    return db['gpu_monitor'], db['node_monitor']


def setup_db(workers_collection):
    """ Sets up the database collections, specifically ensuring the right indices exist."""
    return workers_collection.ensure_index( [("port", ASCENDING), ("ip", ASCENDING), ("pid", ASCENDING)], unique=True )


def cleanup_server_records(gpu_collection, workers_collection):
    """
    Goes into the db and deletes records for workers belongind to servers who are no longer
    registered in the db. Necessary because reaper.py won't be running for that server anymore, and
    reaper.py normally only concerns itself with workers for the server it's running on.
    """
    active_addresses = []

    servers = gpu_collection.find({}, {"ip": True})
    for server in servers:
        active_addresses.append({server["ip"]})

    logger.debug("Active viz server ip addresses: {active}".format(
        active=", ".join(active_addresses) ))

    removed_workers = workers_collection.delete_many({"ip": {"$nin": active_addresses}})

    if removed_workers.deleted_count > 0:
        logging.info("Removed {count} stale worker entries from the database".format(count=removed_workers.deleted_count))

    return removed_workers.deleted_count


def str_to_bytes(human_size):
    """ Converts human-readable string of memory units (e.g. '10 Mib') to bytes as integer."""
    size_str = human_size.replace(' ', '')

    if 'GiB' in size_str:
        return int(size_str.replace('GiB','')) * 1024 * 1024 * 1024
    elif 'MiB' in size_str:
        return int(size_str.replace('MiB','')) * 1024 * 1024
    elif 'KiB' in size_str:
        return int(size_str.replace('KiB','')) * 1024
    else:
        raise SyntaxError('String "{}" could not be converted into an integer number of bytes'.format(human_size))


def log_boundary(metric, value):
    """ Sends the given value to Boundary under the metric name given. If value is not a JSON
    primitive type (number, etc), it should be string that includes quotes as part of the string."""
    # The below template needs to be escaped twice: '{' and '}' need to be escaped as '{{'/'}}' for
    # Python's `format()` string formatter, but '{{'/'}}' needs to be escape because it's also used
    # for Ansible's JINJA2 template engine, so "{" turns into "{{ '{{' }}".
    data = '{{ '{{' }}"source": "{source}", "metric": "{metric}", "measure": {measure}, "timestamp": {timestamp} {{ '}}' }}'.format(
        source=HOSTNAME, metric=metric, measure=value, timestamp=int(time.time()))
    headers = {'content-type': 'application/json'}

    try:
        r = requests.post(url="https://premium-api.boundary.com/v1/measurements", data=data, auth=auth, headers=headers)
    except requests.exceptions.ChunkedEncodingError as chunk_err:
        # Boundary, for some stupid reason, gives the wrong ContentLength field in its response,
        # causing ChunkedEncodingError when the connection closes before requests expects. This is
        # harmless, and the API call seems to succeed anyway.
        pass
    except Exception as err:
        logger.warn("Boundary: error logging metric {metric}: {err}".format(metric=metric, err=str(err)))
    except:
        logger.warn("Boundary: unknown error logging metric {metric}".format(metric=metric))


def get_available_memory():
    # Get GPU free memory from nvidia-smi
    p = subprocess.Popen(["nvidia-smi",
                        "--query-gpu=memory.free",
                        "--format=csv,noheader"], stdout=subprocess.PIPE)
    gpu_data = p.communicate()[0]
    return str_to_bytes(gpu_data)


def gpu_process_usage():
    p = subprocess.Popen(["nvidia-smi",
                            "--query-compute-apps=used_gpu_memory,pid",
                            "--format=csv,noheader"], stdout=subprocess.PIPE)
    gpu_memory_by_process = p.communicate()[0].split('\n')

    logger.debug('GPU driver GPU memory used by process: {}'.format(gpu_memory_by_process))

    gpu_processes = []
    for process in gpu_memory_by_process:
        process_data = process.replace(' ', '').split(',')
        if len(process_data) != 2 or process_data[0] == '':
            continue

        gpu_process_pid = int(process_data[1])
        gpu_memory_used = str_to_bytes(process_data[0])

        logger.debug('Process PID {pid} is using {mem} bytes of GPU memory'.format(pid=gpu_process_pid, mem=gpu_memory_used))
        gpu_processes.append({'pid': gpu_process_pid, 'memory': gpu_memory_used, 'raw': process})

    return gpu_processes


class ProcessTermError(Exception):
    def __init__(self, pid, message):
        self.pid = pid
        self.message = message
    def __str__(self):
        return 'ProcessTermError: could not terminate process {pid}: {message}'.format(pid=self.pid, message=self.message)


def process_is_running(pid):
    """Returns a boolean indicating whether the process with the given PID is currently running."""
    running_pids = [pid for pid in os.listdir('/proc') if pid.isdigit()]
    return str(pid) in running_pids


def kill_process(pid):
    """ """
    logger.warn("Attempting to kill process {pid}".format(pid=pid))
    if process_is_running(pid):
        try:
            os.kill(int(pid), signal.SIGTERM)
        except OSError as oserr:
            # Ignore "no such process" errors; re-raise everything else
            if oserr.errno == 3:
                logger.error("!! Error: could not kill process {pid} because the OS could not find it (though it was running when we checked right before trying to kill it)".format(pid=pid))
                return False
            else:
                logger.error("!! Error: could not kill process {pid} because of an unknown error: {err}".format(pid=pid, err=str(oserr)))
                raise oserr

        if process_is_running(pid):
            logger.error("!! Error: could not kill process {pid}! Our powers are useless! (we sent it a SIGTERM, but the process is still running)".format(pid=pid))
            raise ProcessTermError(pid, "sent SIGTERM, but process still running")

        logger.warn("Successfully killed process {pid}".format(pid=pid))
        return True
    else:
        logger.warn("Process {pid} was not running, so we didn't try to kill it".format(pid=pid))
        return False


def advertise_gpu_memory(gpu_collection):
    """Updates the database with the current amount of GPU memory available on this instance."""
    gpu_memory_free = get_available_memory()
    gpu_collection.update({'ip': ip}, {'$set':
        {
            'gpu_memory_free': gpu_memory_free,
            'updated': datetime.utcnow()
        }}, True)
    logger.debug('GPU memory available: {mem}'.format(mem=gpu_memory_free))
    log_boundary("GPU_FREE", gpu_memory_free)


def advertise_process_memory(workers_collection):
    """Updates the entries of active workers in the database to report how much GPU memory they're
    currently using. Also logs the number of active/inactive workers to Boundary.
    """
    # Update db for each process talking to the GPU
    for process in gpu_process_usage():
        logger.debug("Process GPU data: {}".format(process['raw']))
        workers_collection.update(
            { 'ip': ip, 'pid': int(process['pid']) },
            { '$set': {'gpu_memory' : int(process['memory'])} })

    # Update Boundary
    try:
        active_users = workers_collection.find({"ip": ip, "active": True}).count()
        log_boundary("ACTIVE_USERS", active_users)

        # inactive_workers = workers_collection.find({"ip": ip, "active": False}).count()
        # log_boundary("INACTIVE_WORKERS", inactive_workers)
    except Exception as activity_err:
        console.warn("Error while attempting to count and log active/inactive workers: {err}".format(err=str(activity_err)))


def reap_workers(workers_collection):
    """Checks the database for workers on this instance who have not pinged in WORKER_TIMEOUT, and
    attempts to kill those processes and remove their entry from the database.
    """
    # Select all checkins older than 30 seconds
    zombie_timestamp = datetime.utcnow() - timedelta(seconds=WORKER_TIMEOUT)
    zombie_workers = workers_collection.find({"ip": ip, "updated": {"$lt": zombie_timestamp}})

    logger.debug("Checking for zombie worker processes and reaping them (processes that haven't pinged since {ztime} are considered zombies)".format(ztime=zombie_timestamp))

    for worker in zombie_workers:
        logger.warn("Terminating stale worker. Port: {port}, PID: {pid}".format(port=worker['port'], pid=worker['pid']))

        try:
            if kill_process(int(worker['pid'])):
                logger.info('Reaped worker with PID {pid}'.fomat(worker['pid']))
            else:
                logger.warn('Worker with PID {pid} was not running, so we just removed its ping from the database'.format(pid=worker['pid']))
            workers_collection.remove({"_id": worker['_id']})

        except Exception as e:
            logger.error('Error encountered reaping process "{pid}": {err}'.format(pid=worker['pid'], err=str(e)))


if __name__=="__main__":
    # Connect to central db
    gpu_collection, workers_collection = connect_mongo()

    setup_db(workers_collection)

    tick_count = 0

    while 1:
        try:
            advertise_gpu_memory(gpu_collection)
            reap_workers(workers_collection)
            advertise_process_memory(workers_collection)

            # Do this at a random, but long-ish, interval to save work, and ensure multiple reapers
            # don't all do this at the same time.
            if tick_count <= 0:
                tick_count = random.randint(10, 20)
                logger.debug('Cleaning workers table of records belong to do dead servers')
                cleanup_server_records(gpu_collection, workers_collection)

        except errors.ConnectionFailure:
            logger.error("!! Error: lost connection to the Mongo database. Attempting to reconnect...")
            gpu_collection, workers_collection = connect_mongo()

        finally:
            tick_count -= 1

        time.sleep(25)
