{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Microsoft Sentinel Security Analysis with Graphistry\n",
    "\n",
    "This notebook demonstrates how to use Graphistry with Microsoft Sentinel (Log Analytics) to perform security analysis and visualization using KQL queries.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "1. **Azure Access**: You need access to a Microsoft Sentinel workspace\n",
    "2. **Authentication**: Either Azure CLI (`az login`) or service principal credentials\n",
    "3. **Dependencies**: Install required packages\n",
    "\n",
    "```bash\n",
    "pip install graphistry[sentinel] python-dotenv\n",
    "```\n",
    "\n",
    "## Environment Setup\n",
    "\n",
    "1. Copy `example.env` to `.env` in the same directory as this notebook\n",
    "2. Edit `.env` with your actual credentials:\n",
    "\n",
    "```bash\n",
    "cp example.env .env\n",
    "# Then edit .env with your credentials\n",
    "```\n",
    "\n",
    "The `.env` file should contain:\n",
    "\n",
    "```env\n",
    "# Graphistry credentials (register at https://www.graphistry.com)\n",
    "GRAPHISTRY_PERSONAL_KEY_ID=your_personal_key_id\n",
    "GRAPHISTRY_PERSONAL_KEY_SECRET=your_personal_key_secret\n",
    "\n",
    "# Microsoft Sentinel workspace\n",
    "SENTINEL_WORKSPACE_ID=12345678-1234-1234-1234-123456789abc\n",
    "\n",
    "# Optional: Service Principal authentication (if not using Azure CLI)\n",
    "# AZURE_TENANT_ID=your-tenant-id\n",
    "# AZURE_CLIENT_ID=your-client-id\n",
    "# AZURE_CLIENT_SECRET=your-client-secret\n",
    "```\n",
    "\n",
    "**Important**: The `.env` file is gitignored to avoid committing secrets. Never commit actual credentials!\n",
    "\n",
    "## Getting Started\n",
    "\n",
    "### Option 1: Azure CLI Authentication (Recommended for Development)\n",
    "\n",
    "First, login with Azure CLI:\n",
    "```bash\n",
    "az login\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import graphistry\nfrom datetime import datetime, timedelta\nimport pandas as pd\nimport os\nfrom dotenv import load_dotenv\n\n# Load environment variables from .env file\n# Option 1: Load from current directory (default)\nload_dotenv()\n\n# Option 2: Load from a custom location (uncomment and modify as needed)\n# load_dotenv('~/custom.env')  # Load from home directory\n# load_dotenv('/path/to/your/.env')  # Load from absolute path\n# load_dotenv(os.path.expanduser('~/sentinel-credentials.env'))  # Expand ~ to home directory\n\n# Register for free at https://www.graphistry.com\n# Credentials loaded from .env file\ngraphistry.register(\n    api=3,\n    protocol=\"https\",\n    server=\"hub.graphistry.com\",\n    personal_key_id=os.getenv('GRAPHISTRY_PERSONAL_KEY_ID'),\n    personal_key_secret=os.getenv('GRAPHISTRY_PERSONAL_KEY_SECRET')\n)\n\n# Configure Sentinel connection\n# Workspace ID loaded from .env file\nWORKSPACE_ID = os.getenv('SENTINEL_WORKSPACE_ID')\n\nif not WORKSPACE_ID:\n    raise ValueError(\"SENTINEL_WORKSPACE_ID not found in environment variables. Please check your .env file.\")\n\ng = graphistry.configure_sentinel(\n    workspace_id=WORKSPACE_ID,\n    use_device_auth=True  # Use device code authentication\n)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Service Principal Authentication (Recommended for Production)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Alternative: Service Principal authentication from .env file\n# Uncomment the lines below if you prefer Service Principal over device authentication\n# g = graphistry.configure_sentinel(\n#     workspace_id=os.getenv('SENTINEL_WORKSPACE_ID'),\n#     tenant_id=os.getenv('AZURE_TENANT_ID'),\n#     client_id=os.getenv('AZURE_CLIENT_ID'),\n#     client_secret=os.getenv('AZURE_CLIENT_SECRET')\n# )\n\n# Alternative: Use DefaultAzureCredential (tries Azure CLI, Managed Identity, etc.)\n# g = graphistry.configure_sentinel(\n#     workspace_id=os.getenv('SENTINEL_WORKSPACE_ID')\n# )"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Test the connection\n# Note: If using device authentication, you'll see a code and URL to visit for authentication\ntry:\n    g.sentinel_health_check()\n    print(\"âœ… Successfully connected to Microsoft Sentinel!\")\nexcept Exception as e:\n    print(f\"âŒ Connection failed: {e}\")\n    print(\"ðŸ’¡ If using device auth, make sure to complete the authentication in your browser first.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Available Data\n",
    "\n",
    "Let's start by exploring what tables are available in your Sentinel workspace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# List all available tables\ntry:\n    tables_df = g.sentinel_tables()\n    print(f\"Found {len(tables_df)} tables in workspace\")\n    print(\"\\nSecurity-related tables:\")\n    security_tables = tables_df[tables_df['DataType'].str.contains('Security|Alert|Incident', case=False, na=False)]\n    if not security_tables.empty:\n        print(security_tables['DataType'].tolist())\n    else:\n        print(\"No security-related tables found\")\n    print(f\"\\nAll tables: {tables_df['DataType'].tolist()}\")\nexcept Exception as e:\n    print(f\"Failed to list tables: {e}\")\n    print(\"This might happen if the workspace has no data or insufficient permissions\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Get schema for SecurityEvent table (if available)\ntry:\n    if 'SecurityEvent' in tables_df['DataType'].values:\n        schema = g.sentinel_schema('SecurityEvent')\n        print(\"SecurityEvent table schema:\")\n        print(schema[['ColumnName', 'DataType']].head(10))\n    else:\n        print(\"SecurityEvent table not found in workspace\")\n        print(\"Available tables for schema inspection:\", tables_df['DataType'].head(5).tolist())\nexcept Exception as e:\n    print(f\"Failed to get schema: {e}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Security Analysis Examples\n",
    "\n",
    "### 1. Failed Login Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 users with multiple failed logins\n",
      "       UserPrincipalName  FailureCount  UniqueIPs  \\\n",
      "0  sindre@graphistry.com            12          3   \n",
      "\n",
      "                     LatestFailure  \n",
      "0 2025-09-22 10:14:57.559331+00:00  \n"
     ]
    }
   ],
   "source": [
    "# Query failed login attempts (last 7 days)\n",
    "failed_logins_query = \"\"\"\n",
    "SigninLogs\n",
    "| where TimeGenerated > ago(7d)\n",
    "| where ResultType != \"0\"  // 0 = success\n",
    "| project TimeGenerated, UserPrincipalName, IPAddress, Location, ResultType, ResultDescription\n",
    "| summarize \n",
    "    FailureCount = count(),\n",
    "    UniqueIPs = dcount(IPAddress),\n",
    "    LatestFailure = max(TimeGenerated)\n",
    "    by UserPrincipalName\n",
    "| where FailureCount > 5\n",
    "| order by FailureCount desc\n",
    "| take 50\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    failed_logins = g.kql(failed_logins_query, timespan=timedelta(days=7))\n",
    "    print(f\"Found {len(failed_logins)} users with multiple failed logins\")\n",
    "    print(failed_logins.head())\n",
    "except Exception as e:\n",
    "    print(f\"Query failed: {e}\")\n",
    "    print(\"This might happen if SigninLogs table is not available in your workspace\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Security Alerts Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 security alerts in the last 24 hours\n",
      "No alerts found (this is good!)\n"
     ]
    }
   ],
   "source": [
    "# Query recent security alerts\n",
    "alerts_query = \"\"\"\n",
    "SecurityAlert\n",
    "| where TimeGenerated > ago(24h)\n",
    "| project \n",
    "    TimeGenerated,\n",
    "    AlertName,\n",
    "    AlertSeverity,\n",
    "    CompromisedEntity,\n",
    "    Tactics,\n",
    "    Techniques,\n",
    "    Status\n",
    "| order by TimeGenerated desc\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    alerts = g.kql_last(alerts_query, hours=24)\n",
    "    print(f\"Found {len(alerts)} security alerts in the last 24 hours\")\n",
    "    if len(alerts) > 0:\n",
    "        print(\"\\nAlert severity distribution:\")\n",
    "        print(alerts['AlertSeverity'].value_counts())\n",
    "        print(\"\\nSample alerts:\")\n",
    "        print(alerts[['TimeGenerated', 'AlertName', 'AlertSeverity']].head())\n",
    "    else:\n",
    "        print(\"No alerts found (this is good!)\")\n",
    "except Exception as e:\n",
    "    print(f\"Query failed: {e}\")\n",
    "    print(\"This might happen if SecurityAlert table is not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Network Traffic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query network connections (example with CommonSecurityLog)\n",
    "network_query = \"\"\"\n",
    "CommonSecurityLog\n",
    "| where TimeGenerated > ago(1h)\n",
    "| where isnotempty(SourceIP) and isnotempty(DestinationIP)\n",
    "| project \n",
    "    TimeGenerated,\n",
    "    SourceIP,\n",
    "    DestinationIP,\n",
    "    DestinationPort,\n",
    "    Protocol,\n",
    "    Activity,\n",
    "    DeviceVendor\n",
    "| summarize \n",
    "    ConnectionCount = count(),\n",
    "    UniquePorts = dcount(DestinationPort)\n",
    "    by SourceIP, DestinationIP\n",
    "| where ConnectionCount > 10\n",
    "| order by ConnectionCount desc\n",
    "| take 100\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    network_data = g.kql_last(network_query, hours=1)\n",
    "    print(f\"Found {len(network_data)} significant network connections\")\n",
    "    if len(network_data) > 0:\n",
    "        print(network_data.head())\n",
    "except Exception as e:\n",
    "    print(f\"Query failed: {e}\")\n",
    "    print(\"This might happen if CommonSecurityLog table is not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Visualization\n",
    "\n",
    "Now let's create some graph visualizations from the security data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. User-IP Relationship Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created graph with 7 nodes and 4 edges\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed memoization speedup attempt due to Pandas internal hash function failing. Continuing without memoization speedups.This is fine, but for speedups around skipping re-uploads of previously seen tables, try identifying which columns have types that Pandas cannot hash, and convert them to hashable types like strings.\n"
     ]
    }
   ],
   "source": [
    "# Query for user-IP relationships\n",
    "user_ip_query = \"\"\"\n",
    "SigninLogs\n",
    "| where TimeGenerated > ago(24h)\n",
    "| where isnotempty(UserPrincipalName) and isnotempty(IPAddress)\n",
    "| project UserPrincipalName, IPAddress, TimeGenerated, ResultType, Location\n",
    "| summarize \n",
    "    LoginCount = count(),\n",
    "    FailureCount = countif(ResultType != \"0\"),\n",
    "    LatestLogin = max(TimeGenerated),\n",
    "    Locations = make_set(Location)\n",
    "    by UserPrincipalName, IPAddress\n",
    "| extend RiskScore = FailureCount * 2 + iff(LoginCount == 1, 1, 0)\n",
    "| take 500\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    user_ip_data = g.kql_last(user_ip_query, hours=24)\n",
    "    \n",
    "    if len(user_ip_data) > 0:\n",
    "        # Create nodes and edges for graph visualization\n",
    "        \n",
    "        # Create user nodes\n",
    "        users = user_ip_data[['UserPrincipalName']].drop_duplicates()\n",
    "        users['node_type'] = 'user'\n",
    "        users['node_id'] = users['UserPrincipalName']\n",
    "        users['node_label'] = users['UserPrincipalName']\n",
    "        \n",
    "        # Create IP nodes  \n",
    "        ips = user_ip_data[['IPAddress']].drop_duplicates()\n",
    "        ips['node_type'] = 'ip'\n",
    "        ips['node_id'] = ips['IPAddress']\n",
    "        ips['node_label'] = ips['IPAddress']\n",
    "        \n",
    "        # Combine nodes\n",
    "        nodes = pd.concat([\n",
    "            users[['node_id', 'node_label', 'node_type']],\n",
    "            ips[['node_id', 'node_label', 'node_type']]\n",
    "        ], ignore_index=True)\n",
    "        \n",
    "        # Create edges\n",
    "        edges = user_ip_data.copy()\n",
    "        edges['source'] = edges['UserPrincipalName']\n",
    "        edges['target'] = edges['IPAddress']\n",
    "        edges['edge_weight'] = edges['LoginCount']\n",
    "        edges['edge_color'] = edges['RiskScore'].apply(\n",
    "            lambda x: 'red' if x > 5 else 'orange' if x > 2 else 'green'\n",
    "        )\n",
    "        \n",
    "        # Create and plot graph\n",
    "        graph = g.nodes(nodes, node='node_id')\\\n",
    "                 .edges(edges, source='source', destination='target')\\\n",
    "                 .encode_point_color('node_type')\\\n",
    "                 .encode_edge_color('edge_color')\\\n",
    "                 .settings(url_params={'splashAfter': 'false'})\n",
    "        \n",
    "        print(f\"Created graph with {len(nodes)} nodes and {len(edges)} edges\")\n",
    "        \n",
    "        # Plot the graph\n",
    "        graph.plot()\n",
    "    else:\n",
    "        print(\"No data available for user-IP graph\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Graph creation failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Alert Correlation Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query for alert correlations\n",
    "alert_correlation_query = \"\"\"\n",
    "SecurityAlert\n",
    "| where TimeGenerated > ago(7d)\n",
    "| project \n",
    "    AlertName,\n",
    "    CompromisedEntity,\n",
    "    Tactics,\n",
    "    AlertSeverity,\n",
    "    TimeGenerated\n",
    "| extend EntityType = case(\n",
    "    CompromisedEntity contains \"@\", \"User\",\n",
    "    CompromisedEntity matches regex @\"\\\\b(?:[0-9]{1,3}\\\\.){3}[0-9]{1,3}\\\\b\", \"IP\",\n",
    "    \"Host\"\n",
    ")\n",
    "| summarize \n",
    "    AlertCount = count(),\n",
    "    Severities = make_set(AlertSeverity),\n",
    "    TacticsList = make_set(Tactics)\n",
    "    by AlertName, CompromisedEntity, EntityType\n",
    "| where AlertCount > 1\n",
    "| take 200\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    alert_data = g.kql(alert_correlation_query, timespan=timedelta(days=7))\n",
    "    \n",
    "    if len(alert_data) > 0:\n",
    "        # Create alert type nodes\n",
    "        alert_types = alert_data[['AlertName']].drop_duplicates()\n",
    "        alert_types['node_type'] = 'alert'\n",
    "        alert_types['node_id'] = alert_types['AlertName']\n",
    "        alert_types['node_label'] = alert_types['AlertName']\n",
    "        \n",
    "        # Create entity nodes\n",
    "        entities = alert_data[['CompromisedEntity', 'EntityType']].drop_duplicates()\n",
    "        entities['node_type'] = entities['EntityType'].str.lower()\n",
    "        entities['node_id'] = entities['CompromisedEntity']\n",
    "        entities['node_label'] = entities['CompromisedEntity']\n",
    "        \n",
    "        # Combine nodes\n",
    "        alert_nodes = pd.concat([\n",
    "            alert_types[['node_id', 'node_label', 'node_type']],\n",
    "            entities[['node_id', 'node_label', 'node_type']]\n",
    "        ], ignore_index=True)\n",
    "        \n",
    "        # Create edges (alert -> entity)\n",
    "        alert_edges = alert_data.copy()\n",
    "        alert_edges['source'] = alert_edges['AlertName']\n",
    "        alert_edges['target'] = alert_edges['CompromisedEntity']\n",
    "        alert_edges['edge_weight'] = alert_edges['AlertCount']\n",
    "        \n",
    "        # Create and plot graph\n",
    "        alert_graph = g.nodes(alert_nodes, node='node_id')\\\n",
    "                       .edges(alert_edges, source='source', destination='target')\\\n",
    "                       .encode_point_color('node_type')\\\n",
    "                       .encode_edge_size('edge_weight')\\\n",
    "                       .settings(url_params={'splashAfter': 'false'})\n",
    "        \n",
    "        print(f\"Created alert correlation graph with {len(alert_nodes)} nodes and {len(alert_edges)} edges\")\n",
    "        \n",
    "        # Plot the graph\n",
    "        alert_graph.plot()\n",
    "    else:\n",
    "        print(\"No alert correlation data available\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Alert correlation graph failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Analysis\n",
    "\n",
    "### Multi-table Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complex query joining multiple data sources\n",
    "correlation_query = \"\"\"\n",
    "// Get security incidents\n",
    "let incidents = SecurityIncident\n",
    "| where TimeGenerated > ago(30d)\n",
    "| project IncidentNumber, Title, Severity, Status, Owner;\n",
    "\n",
    "// Get related alerts  \n",
    "let alerts = SecurityAlert\n",
    "| where TimeGenerated > ago(30d)\n",
    "| project AlertName, CompromisedEntity, AlertSeverity, Tactics;\n",
    "\n",
    "// Join and analyze\n",
    "incidents\n",
    "| join kind=inner (alerts) on $left.Title == $right.AlertName\n",
    "| summarize \n",
    "    IncidentCount = dcount(IncidentNumber),\n",
    "    AffectedEntities = dcount(CompromisedEntity),\n",
    "    TacticsUsed = make_set(Tactics)\n",
    "    by Title, Severity\n",
    "| order by IncidentCount desc\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    correlation_data = g.kql(correlation_query, timespan=timedelta(days=30))\n",
    "    print(f\"Found {len(correlation_data)} incident-alert correlations\")\n",
    "    if len(correlation_data) > 0:\n",
    "        print(correlation_data.head())\n",
    "except Exception as e:\n",
    "    print(f\"Correlation query failed: {e}\")\n",
    "    print(\"This requires both SecurityIncident and SecurityAlert tables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Summary\n\nThis notebook demonstrated:\n\n1. **Connecting to Microsoft Sentinel** using Azure authentication (device code, service principal, or DefaultAzureCredential)\n2. **Exploring available data** with `sentinel_tables()` and `sentinel_schema()`\n3. **Security analysis** using KQL queries for:\n   - Failed login analysis\n   - Security alerts monitoring\n   - Network traffic analysis\n4. **Graph visualization** of:\n   - User-IP relationships\n   - Alert correlations\n5. **Advanced correlation** across multiple data sources\n\n## Next Steps\n\n- **Customize queries** for your specific security use cases and available data tables\n- **Create automated dashboards** by scheduling notebook execution\n- **Integrate with threat intelligence** feeds using additional KQL joins\n- **Build detection rules** based on graph patterns you discover\n- **Scale analysis** by adjusting time windows and data volumes\n\n## Troubleshooting Tips\n\n- **No data found**: Some workspaces may not have SecurityEvent, SigninLogs, or SecurityAlert tables\n- **Authentication issues**: Try `az login` first, or check your service principal credentials\n- **Permission errors**: Ensure your account has Log Analytics Reader permissions\n- **Empty results**: Adjust time ranges - some workspaces have limited data retention\n\n## Resources\n\n- [Microsoft Sentinel KQL Reference](https://docs.microsoft.com/en-us/azure/data-explorer/kusto/query/)\n- [Graphistry Documentation](https://pygraphistry.readthedocs.io/)\n- [Azure Monitor Query Documentation](https://docs.microsoft.com/en-us/python/api/azure-monitor-query/)\n- [Sentinel Data Connectors](https://docs.microsoft.com/en-us/azure/sentinel/connect-data-sources)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Graphistry Dev",
   "language": "python",
   "name": "graphistry-dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}