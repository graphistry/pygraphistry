{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GFQL Validation for LLMs and Automation\n",
    "\n",
    "Learn how to integrate GFQL validation with Large Language Models and automation pipelines.\n",
    "\n",
    "## Target Audience\n",
    "- AI/ML Engineers building GFQL generation systems\n",
    "- Developers integrating LLMs with graph queries\n",
    "- Teams building automated query generation pipelines\n",
    "\n",
    "## What You'll Learn\n",
    "- Structured error formats for LLM consumption\n",
    "- Automated fix suggestions and corrections\n",
    "- Integration patterns with LLM APIs\n",
    "- Building robust query generation pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports\n",
    "import json\n",
    "import pandas as pd\n",
    "import graphistry\n",
    "from typing import Dict, List, Any, Optional\n",
    "\n",
    "from graphistry.compute.validate import (\n",
    "    validate_syntax,\n",
    "    validate_schema,\n",
    "    validate_query,\n",
    "    extract_schema_from_dataframes,\n",
    "    ValidationIssue\n",
    ")\n",
    "\n",
    "print(f\"PyGraphistry version: {graphistry.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON Serialization Basics\n",
    "\n",
    "Convert validation results to structured formats for LLMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper to serialize ValidationIssue to JSON\n",
    "def validation_issue_to_dict(issue: ValidationIssue) -> Dict[str, Any]:\n",
    "    \"\"\"Convert ValidationIssue to JSON-serializable dict.\"\"\"\n",
    "    return {\n",
    "        \"level\": issue.level,\n",
    "        \"message\": issue.message,\n",
    "        \"operation_index\": issue.operation_index,\n",
    "        \"field\": issue.field,\n",
    "        \"suggestion\": issue.suggestion\n",
    "    }\n",
    "\n",
    "# Example with invalid query\n",
    "invalid_query = [\n",
    "    {\"type\": \"node\"},  # Wrong type\n",
    "    {\"type\": \"e_forward\", \"filter\": {\"weight\": \"high\"}}  # Invalid filter\n",
    "]\n",
    "\n",
    "issues = validate_syntax(invalid_query)\n",
    "\n",
    "# Convert to JSON\n",
    "json_output = {\n",
    "    \"query\": invalid_query,\n",
    "    \"valid\": len(issues) == 0,\n",
    "    \"error_count\": sum(1 for i in issues if i.level == \"error\"),\n",
    "    \"warning_count\": sum(1 for i in issues if i.level == \"warning\"),\n",
    "    \"issues\": [validation_issue_to_dict(issue) for issue in issues]\n",
    "}\n",
    "\n",
    "print(\"JSON output for LLM:\")\n",
    "print(json.dumps(json_output, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structured Error Formats\n",
    "\n",
    "Create error formats optimized for LLM understanding and correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_llm_error_report(query: List[Dict], issues: List[ValidationIssue]) -> Dict[str, Any]:\n",
    "    \"\"\"Create structured error report for LLMs.\"\"\"\n",
    "    \n",
    "    # Categorize errors\n",
    "    errors_by_type = {\n",
    "        \"syntax_errors\": [],\n",
    "        \"semantic_warnings\": [],\n",
    "        \"schema_errors\": []\n",
    "    }\n",
    "    \n",
    "    for issue in issues:\n",
    "        issue_dict = validation_issue_to_dict(issue)\n",
    "        \n",
    "        # Add context about the problematic operation\n",
    "        if issue.operation_index is not None and issue.operation_index < len(query):\n",
    "            issue_dict[\"operation\"] = query[issue.operation_index]\n",
    "        \n",
    "        # Categorize\n",
    "        if \"Invalid operation type\" in issue.message or \"Invalid filter\" in issue.message:\n",
    "            errors_by_type[\"syntax_errors\"].append(issue_dict)\n",
    "        elif \"Column\" in issue.message and \"not found\" in issue.message:\n",
    "            errors_by_type[\"schema_errors\"].append(issue_dict)\n",
    "        else:\n",
    "            errors_by_type[\"semantic_warnings\"].append(issue_dict)\n",
    "    \n",
    "    return {\n",
    "        \"validation_status\": \"failed\" if any(errors_by_type.values()) else \"passed\",\n",
    "        \"total_issues\": len(issues),\n",
    "        \"fixable_issues\": sum(1 for i in issues if i.suggestion is not None),\n",
    "        \"errors_by_type\": errors_by_type,\n",
    "        \"requires_schema\": len(errors_by_type[\"schema_errors\"]) > 0\n",
    "    }\n",
    "\n",
    "# Test with complex errors\n",
    "complex_invalid = [\n",
    "    {\"type\": \"n\", \"filter\": {\"unknown_col\": {\"eq\": \"value\"}}},\n",
    "    {\"type\": \"edge_forward\"},  # Wrong type\n",
    "    {\"type\": \"n\", \"filter\": {\"score\": {\"equals\": 100}}}  # Wrong operator\n",
    "]\n",
    "\n",
    "# Create sample schema\n",
    "sample_df = pd.DataFrame({\"id\": [1], \"name\": [\"test\"], \"score\": [100]})\n",
    "schema = extract_schema_from_dataframes(sample_df, pd.DataFrame())\n",
    "\n",
    "# Validate syntax and schema\n",
    "syntax_issues = validate_syntax(complex_invalid)\n",
    "schema_issues = validate_schema(complex_invalid, schema)\n",
    "all_issues = syntax_issues + schema_issues\n",
    "\n",
    "report = create_llm_error_report(complex_invalid, all_issues)\n",
    "print(\"LLM Error Report:\")\n",
    "print(json.dumps(report, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automated Fix Suggestions\n",
    "\n",
    "Generate actionable suggestions for fixing validation errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def suggest_fixes(query: List[Dict], issues: List[ValidationIssue], \n",
    "                  schema: Optional[Any] = None) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Generate fix suggestions for validation issues.\"\"\"\n",
    "    fixes = []\n",
    "    \n",
    "    for issue in issues:\n",
    "        fix = {\n",
    "            \"issue\": validation_issue_to_dict(issue),\n",
    "            \"fixes\": []\n",
    "        }\n",
    "        \n",
    "        # Fix invalid operation types\n",
    "        if \"Invalid operation type\" in issue.message:\n",
    "            if issue.operation_index is not None:\n",
    "                op = query[issue.operation_index]\n",
    "                if op.get(\"type\") == \"node\":\n",
    "                    fix[\"fixes\"].append({\n",
    "                        \"action\": \"replace\",\n",
    "                        \"path\": f\"[{issue.operation_index}].type\",\n",
    "                        \"old_value\": \"node\",\n",
    "                        \"new_value\": \"n\"\n",
    "                    })\n",
    "                elif op.get(\"type\") == \"edge_forward\":\n",
    "                    fix[\"fixes\"].append({\n",
    "                        \"action\": \"replace\",\n",
    "                        \"path\": f\"[{issue.operation_index}].type\",\n",
    "                        \"old_value\": \"edge_forward\",\n",
    "                        \"new_value\": \"e_forward\"\n",
    "                    })\n",
    "        \n",
    "        # Fix invalid operators\n",
    "        if \"Invalid operator\" in issue.message:\n",
    "            if \"equals\" in issue.message:\n",
    "                fix[\"fixes\"].append({\n",
    "                    \"action\": \"replace_key\",\n",
    "                    \"description\": \"Change 'equals' to 'eq'\",\n",
    "                    \"example\": '{\"score\": {\"eq\": 100}}'\n",
    "                })\n",
    "            elif \"greater\" in issue.message:\n",
    "                fix[\"fixes\"].append({\n",
    "                    \"action\": \"replace_key\",\n",
    "                    \"description\": \"Change 'greater' to 'gt'\",\n",
    "                    \"example\": '{\"score\": {\"gt\": 100}}'\n",
    "                })\n",
    "        \n",
    "        # Fix column not found\n",
    "        if \"Column\" in issue.message and \"not found\" in issue.message and schema:\n",
    "            # Extract column name from message\n",
    "            import re\n",
    "            match = re.search(r\"Column '(\\w+)'\", issue.message)\n",
    "            if match:\n",
    "                missing_col = match.group(1)\n",
    "                # Suggest similar columns\n",
    "                if hasattr(schema, 'node_columns'):\n",
    "                    available = list(schema.node_columns.keys())\n",
    "                    fix[\"fixes\"].append({\n",
    "                        \"action\": \"use_available_column\",\n",
    "                        \"missing\": missing_col,\n",
    "                        \"available\": available,\n",
    "                        \"suggestion\": f\"Use one of: {', '.join(available)}\"\n",
    "                    })\n",
    "        \n",
    "        if fix[\"fixes\"]:\n",
    "            fixes.append(fix)\n",
    "    \n",
    "    return fixes\n",
    "\n",
    "# Test fix suggestions\n",
    "fixes = suggest_fixes(complex_invalid, all_issues, schema)\n",
    "print(\"Fix Suggestions:\")\n",
    "print(json.dumps(fixes, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Categorization\n",
    "\n",
    "Categorize errors for prioritized fixing by LLMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_and_prioritize_errors(issues: List[ValidationIssue]) -> Dict[str, Any]:\n",
    "    \"\"\"Categorize and prioritize errors for LLM processing.\"\"\"\n",
    "    \n",
    "    categories = {\n",
    "        \"critical\": [],    # Must fix - query won't run\n",
    "        \"important\": [],   # Should fix - query may fail on data\n",
    "        \"suggested\": []    # Nice to fix - performance/style\n",
    "    }\n",
    "    \n",
    "    for issue in issues:\n",
    "        issue_dict = validation_issue_to_dict(issue)\n",
    "        \n",
    "        # Critical: syntax errors\n",
    "        if issue.level == \"error\" and any(keyword in issue.message for keyword in \n",
    "            [\"Invalid operation\", \"Invalid filter\", \"Invalid predicate\"]):\n",
    "            categories[\"critical\"].append(issue_dict)\n",
    "        \n",
    "        # Important: schema errors\n",
    "        elif \"not found\" in issue.message or \"type mismatch\" in issue.message:\n",
    "            categories[\"important\"].append(issue_dict)\n",
    "        \n",
    "        # Suggested: warnings\n",
    "        elif issue.level == \"warning\":\n",
    "            categories[\"suggested\"].append(issue_dict)\n",
    "        \n",
    "        else:\n",
    "            categories[\"important\"].append(issue_dict)\n",
    "    \n",
    "    return {\n",
    "        \"categories\": categories,\n",
    "        \"fix_order\": [\n",
    "            \"1. Fix all critical errors first (syntax)\",\n",
    "            \"2. Then fix important errors (schema/types)\",\n",
    "            \"3. Finally address suggested improvements\"\n",
    "        ],\n",
    "        \"estimated_iterations\": max(1, len(categories[\"critical\"]) + \n",
    "                                   (1 if categories[\"important\"] else 0))\n",
    "    }\n",
    "\n",
    "# Test categorization\n",
    "categorized = categorize_and_prioritize_errors(all_issues)\n",
    "print(\"Error Categorization for LLM:\")\n",
    "print(json.dumps(categorized, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Integration Patterns\n",
    "\n",
    "Common patterns for integrating validation with LLM query generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GFQLValidationPipeline:\n",
    "    \"\"\"Pipeline for validating and fixing LLM-generated GFQL queries.\"\"\"\n",
    "    \n",
    "    def __init__(self, schema=None, max_iterations=3):\n",
    "        self.schema = schema\n",
    "        self.max_iterations = max_iterations\n",
    "        self.history = []\n",
    "    \n",
    "    def validate_and_report(self, query: List[Dict]) -> Dict[str, Any]:\n",
    "        \"\"\"Validate query and create comprehensive report.\"\"\"\n",
    "        \n",
    "        # Syntax validation\n",
    "        syntax_issues = validate_syntax(query)\n",
    "        \n",
    "        # Schema validation if available\n",
    "        schema_issues = []\n",
    "        if self.schema:\n",
    "            schema_issues = validate_schema(query, self.schema)\n",
    "        \n",
    "        all_issues = syntax_issues + schema_issues\n",
    "        \n",
    "        # Create report\n",
    "        report = {\n",
    "            \"query\": query,\n",
    "            \"iteration\": len(self.history),\n",
    "            \"valid\": len(all_issues) == 0,\n",
    "            \"issues\": [validation_issue_to_dict(i) for i in all_issues],\n",
    "            \"error_report\": create_llm_error_report(query, all_issues),\n",
    "            \"fixes\": suggest_fixes(query, all_issues, self.schema),\n",
    "            \"categories\": categorize_and_prioritize_errors(all_issues)\n",
    "        }\n",
    "        \n",
    "        self.history.append(report)\n",
    "        return report\n",
    "    \n",
    "    def create_llm_prompt(self, report: Dict[str, Any]) -> str:\n",
    "        \"\"\"Create prompt for LLM to fix the query.\"\"\"\n",
    "        \n",
    "        if report[\"valid\"]:\n",
    "            return \"Query is valid. No fixes needed.\"\n",
    "        \n",
    "        prompt = f\"\"\"Fix the following GFQL query based on validation errors:\n",
    "\n",
    "Current Query:\n",
    "{json.dumps(report['query'], indent=2)}\n",
    "\n",
    "Errors to Fix:\n",
    "{json.dumps(report['categories']['categories'], indent=2)}\n",
    "\n",
    "Suggested Fixes:\n",
    "{json.dumps(report['fixes'], indent=2)}\n",
    "\n",
    "Please provide the corrected query as a JSON array.\n",
    "Fix critical errors first, then important ones.\n",
    "\"\"\"\n",
    "        return prompt\n",
    "\n",
    "# Example usage\n",
    "pipeline = GFQLValidationPipeline(schema=schema)\n",
    "\n",
    "# Validate problematic query\n",
    "report = pipeline.validate_and_report(complex_invalid)\n",
    "\n",
    "print(\"Validation Pipeline Report:\")\n",
    "print(f\"Valid: {report['valid']}\")\n",
    "print(f\"Total Issues: {len(report['issues'])}\")\n",
    "print(f\"\\nLLM Prompt Preview:\")\n",
    "print(pipeline.create_llm_prompt(report)[:500] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mock LLM Examples\n",
    "\n",
    "Simulate LLM query generation and iterative refinement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MockLLM:\n",
    "    \"\"\"Mock LLM for demonstrating validation integration.\"\"\"\n",
    "    \n",
    "    def generate_query(self, natural_language: str) -> List[Dict]:\n",
    "        \"\"\"Simulate LLM generating GFQL from natural language.\"\"\"\n",
    "        \n",
    "        # Simulate common LLM mistakes\n",
    "        if \"high risk users\" in natural_language.lower():\n",
    "            return [\n",
    "                {\"type\": \"node\", \"filter\": {\"user_type\": {\"equals\": \"user\"}}},  # Wrong!\n",
    "                {\"type\": \"e_forward\"},\n",
    "                {\"type\": \"n\", \"filter\": {\"risk_score\": {\"greater\": 80}}}  # Wrong operator\n",
    "            ]\n",
    "        \n",
    "        return [{\"type\": \"n\"}]  # Default\n",
    "    \n",
    "    def fix_query(self, query: List[Dict], fixes: List[Dict]) -> List[Dict]:\n",
    "        \"\"\"Simulate LLM applying fixes.\"\"\"\n",
    "        import copy\n",
    "        fixed = copy.deepcopy(query)\n",
    "        \n",
    "        # Apply some fixes\n",
    "        for fix in fixes:\n",
    "            for suggested_fix in fix.get(\"fixes\", []):\n",
    "                if suggested_fix[\"action\"] == \"replace\":\n",
    "                    # Simple fix simulation\n",
    "                    if \"node\" in str(fixed):\n",
    "                        fixed = json.loads(json.dumps(fixed).replace('\"node\"', '\"n\"'))\n",
    "                    if \"equals\" in str(fixed):\n",
    "                        fixed = json.loads(json.dumps(fixed).replace('\"equals\"', '\"eq\"'))\n",
    "                    if \"greater\" in str(fixed):\n",
    "                        fixed = json.loads(json.dumps(fixed).replace('\"greater\"', '\"gt\"'))\n",
    "        \n",
    "        return fixed\n",
    "\n",
    "# Demonstrate iterative refinement\n",
    "llm = MockLLM()\n",
    "pipeline = GFQLValidationPipeline(schema=schema, max_iterations=3)\n",
    "\n",
    "# Initial generation\n",
    "nl_query = \"Find high risk users connected to recent transactions\"\n",
    "print(f\"Natural Language: {nl_query}\\n\")\n",
    "\n",
    "query = llm.generate_query(nl_query)\n",
    "print(f\"Initial LLM Query:\")\n",
    "print(json.dumps(query, indent=2))\n",
    "\n",
    "# Iterative refinement\n",
    "for i in range(pipeline.max_iterations):\n",
    "    print(f\"\\n--- Iteration {i+1} ---\")\n",
    "    \n",
    "    report = pipeline.validate_and_report(query)\n",
    "    \n",
    "    if report[\"valid\"]:\n",
    "        print(\"✅ Query is valid!\")\n",
    "        break\n",
    "    \n",
    "    print(f\"Issues found: {len(report['issues'])}\")\n",
    "    \n",
    "    # LLM fixes the query\n",
    "    query = llm.fix_query(query, report[\"fixes\"])\n",
    "    print(f\"Fixed query:\")\n",
    "    print(json.dumps(query, indent=2))\n",
    "\n",
    "print(f\"\\nFinal validation history: {len(pipeline.history)} iterations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate more complex LLM interaction\n",
    "def simulate_llm_conversation(natural_language: str, schema=None):\n",
    "    \"\"\"Simulate a full LLM conversation with validation feedback.\"\"\"\n",
    "    \n",
    "    print(f\"User: {natural_language}\")\n",
    "    print(\"\\nLLM: I'll create a GFQL query for that.\\n\")\n",
    "    \n",
    "    # Initial attempt (with intentional errors)\n",
    "    if \"products purchased by VIP customers\" in natural_language:\n",
    "        attempt1 = [\n",
    "            {\"type\": \"n\", \"filter\": {\"customer_type\": {\"eq\": \"VIP\"}}},\n",
    "            {\"type\": \"edge\", \"filter\": {\"action\": {\"eq\": \"purchase\"}}},\n",
    "            {\"type\": \"n\", \"filter\": {\"type\": {\"eq\": \"product\"}}}\n",
    "        ]\n",
    "    else:\n",
    "        attempt1 = [{\"type\": \"nodes\"}]  # Generic error\n",
    "    \n",
    "    print(\"First attempt:\")\n",
    "    print(json.dumps(attempt1, indent=2))\n",
    "    \n",
    "    # Validate\n",
    "    issues = validate_syntax(attempt1)\n",
    "    if schema:\n",
    "        issues.extend(validate_schema(attempt1, schema))\n",
    "    \n",
    "    if issues:\n",
    "        print(\"\\nValidation found issues:\")\n",
    "        for issue in issues[:3]:  # Show first 3\n",
    "            print(f\"- {issue.level}: {issue.message}\")\n",
    "            if issue.suggestion:\n",
    "                print(f\"  Suggestion: {issue.suggestion}\")\n",
    "        \n",
    "        print(\"\\nLLM: Let me fix those issues...\\n\")\n",
    "        \n",
    "        # Fixed version\n",
    "        if \"products purchased by VIP customers\" in natural_language:\n",
    "            attempt2 = [\n",
    "                {\"type\": \"n\", \"filter\": {\"type\": {\"eq\": \"customer\"}}},  # Fixed column\n",
    "                {\"type\": \"e_forward\"},  # Fixed type\n",
    "                {\"type\": \"n\", \"filter\": {\"type\": {\"eq\": \"product\"}}}\n",
    "            ]\n",
    "        else:\n",
    "            attempt2 = [{\"type\": \"n\"}]  # Fixed\n",
    "        \n",
    "        print(\"Fixed query:\")\n",
    "        print(json.dumps(attempt2, indent=2))\n",
    "        \n",
    "        # Re-validate\n",
    "        final_issues = validate_syntax(attempt2)\n",
    "        if not final_issues:\n",
    "            print(\"\\n✅ Query is now valid!\")\n",
    "        else:\n",
    "            print(f\"\\n⚠️  Still has {len(final_issues)} issues\")\n",
    "    else:\n",
    "        print(\"\\n✅ Query is valid on first attempt!\")\n",
    "\n",
    "# Test conversations\n",
    "print(\"=== Conversation 1 ===\")\n",
    "simulate_llm_conversation(\"Show me products purchased by VIP customers\", schema)\n",
    "\n",
    "print(\"\\n\\n=== Conversation 2 ===\")\n",
    "simulate_llm_conversation(\"Find all nodes in the graph\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Engineering for GFQL\n",
    "\n",
    "Best practices for prompting LLMs to generate valid GFQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gfql_system_prompt(schema=None) -> str:\n",
    "    \"\"\"Create system prompt for LLMs generating GFQL.\"\"\"\n",
    "    \n",
    "    prompt = \"\"\"You are a GFQL (Graph Frame Query Language) expert. \n",
    "\n",
    "GFQL Rules:\n",
    "1. Queries are JSON arrays of operations\n",
    "2. Valid operation types: \"n\" (node), \"e_forward\", \"e_reverse\", \"e\" (edge)\n",
    "3. Filters use operators: eq, ne, gt, gte, lt, lte, contains, regex, in, between\n",
    "4. Complex filters use _and, _or for combining conditions\n",
    "5. Always validate column names against the schema\n",
    "\n",
    "Common Patterns:\n",
    "- Node filter: {\"type\": \"n\", \"filter\": {\"column\": {\"op\": value}}}\n",
    "- Edge traversal: {\"type\": \"e_forward\", \"hops\": 1}\n",
    "- Named operations: {\"type\": \"n\", \"name\": \"my_nodes\"}\n",
    "\"\"\"\n",
    "    \n",
    "    if schema and hasattr(schema, 'node_columns'):\n",
    "        prompt += f\"\\n\\nAvailable columns:\\n\"\n",
    "        prompt += f\"Nodes: {list(schema.node_columns.keys())}\\n\"\n",
    "        if hasattr(schema, 'edge_columns'):\n",
    "            prompt += f\"Edges: {list(schema.edge_columns.keys())}\\n\"\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "# Generate prompts\n",
    "print(\"System Prompt for LLM:\")\n",
    "print(create_gfql_system_prompt(schema))\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Example user prompts with expected GFQL\n",
    "example_prompts = [\n",
    "    {\n",
    "        \"user\": \"Find all customers\",\n",
    "        \"gfql\": [{\"type\": \"n\", \"filter\": {\"type\": {\"eq\": \"customer\"}}}]\n",
    "    },\n",
    "    {\n",
    "        \"user\": \"Show nodes with score above 90\",\n",
    "        \"gfql\": [{\"type\": \"n\", \"filter\": {\"score\": {\"gt\": 90}}}]\n",
    "    },\n",
    "    {\n",
    "        \"user\": \"Find customers and their connections\",\n",
    "        \"gfql\": [\n",
    "            {\"type\": \"n\", \"filter\": {\"type\": {\"eq\": \"customer\"}}},\n",
    "            {\"type\": \"e_forward\", \"hops\": 1},\n",
    "            {\"type\": \"n\"}\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"Example Prompts for Training:\")\n",
    "for ex in example_prompts:\n",
    "    print(f\"\\nUser: {ex['user']}\")\n",
    "    print(f\"GFQL: {json.dumps(ex['gfql'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Practices\n",
    "\n",
    "Key recommendations for LLM integration with GFQL validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best practices demonstration\n",
    "class LLMIntegrationBestPractices:\n",
    "    \"\"\"Demonstrate best practices for LLM-GFQL integration.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def validate_before_execution(query):\n",
    "        \"\"\"Always validate before executing.\"\"\"\n",
    "        issues = validate_syntax(query)\n",
    "        if issues:\n",
    "            return {\"execute\": False, \"reason\": \"Validation failed\", \"issues\": issues}\n",
    "        return {\"execute\": True}\n",
    "    \n",
    "    @staticmethod\n",
    "    def provide_schema_context(schema):\n",
    "        \"\"\"Give LLMs schema information.\"\"\"\n",
    "        context = {\n",
    "            \"node_columns\": {},\n",
    "            \"edge_columns\": {}\n",
    "        }\n",
    "        \n",
    "        if hasattr(schema, 'node_columns'):\n",
    "            for col, dtype in schema.node_columns.items():\n",
    "                context[\"node_columns\"][col] = {\n",
    "                    \"type\": str(dtype),\n",
    "                    \"operators\": [\"eq\", \"ne\", \"in\"] if \"object\" in str(dtype) \n",
    "                                else [\"eq\", \"ne\", \"gt\", \"gte\", \"lt\", \"lte\"]\n",
    "                }\n",
    "        \n",
    "        return context\n",
    "    \n",
    "    @staticmethod\n",
    "    def implement_retry_logic(query, max_retries=3):\n",
    "        \"\"\"Implement exponential backoff for fixes.\"\"\"\n",
    "        import time\n",
    "        \n",
    "        for attempt in range(max_retries):\n",
    "            issues = validate_syntax(query)\n",
    "            if not issues:\n",
    "                return {\"success\": True, \"attempts\": attempt + 1}\n",
    "            \n",
    "            # Simulate fix attempt\n",
    "            time.sleep(0.1 * (2 ** attempt))  # Exponential backoff\n",
    "            \n",
    "        return {\"success\": False, \"attempts\": max_retries}\n",
    "\n",
    "# Demonstrate best practices\n",
    "bp = LLMIntegrationBestPractices()\n",
    "\n",
    "print(\"1. Always Validate Before Execution:\")\n",
    "test_query = [{\"type\": \"n\"}, {\"type\": \"invalid\"}]\n",
    "result = bp.validate_before_execution(test_query)\n",
    "print(f\"   Execute: {result['execute']}\")\n",
    "if not result['execute']:\n",
    "    print(f\"   Reason: {result['reason']}\")\n",
    "\n",
    "print(\"\\n2. Provide Schema Context to LLMs:\")\n",
    "context = bp.provide_schema_context(schema)\n",
    "print(f\"   Schema context: {json.dumps(context, indent=2)[:200]}...\")\n",
    "\n",
    "print(\"\\n3. Implement Retry Logic:\")\n",
    "retry_result = bp.implement_retry_logic([{\"type\": \"n\"}])\n",
    "print(f\"   Success: {retry_result['success']} in {retry_result['attempts']} attempt(s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary & Resources\n",
    "\n",
    "### Key Takeaways\n",
    "1. **Structured Formats**: Convert validation to JSON for LLM consumption\n",
    "2. **Error Categorization**: Prioritize fixes (critical → important → suggested)\n",
    "3. **Iterative Refinement**: Use validation feedback for query improvement\n",
    "4. **Schema Context**: Always provide available columns to LLMs\n",
    "5. **Prompt Engineering**: Use specific GFQL rules and examples\n",
    "\n",
    "### Integration Checklist\n",
    "- ✅ Serialize validation issues to JSON\n",
    "- ✅ Implement fix suggestion generation\n",
    "- ✅ Create iterative validation pipeline\n",
    "- ✅ Provide schema context in prompts\n",
    "- ✅ Handle rate limiting and retries\n",
    "- ✅ Log validation metrics\n",
    "\n",
    "### Next Steps\n",
    "- Integrate with real LLM providers (OpenAI, Anthropic, etc.)\n",
    "- Build production validation pipelines\n",
    "- Create domain-specific GFQL templates\n",
    "- Monitor and improve generation accuracy\n",
    "\n",
    "### Resources\n",
    "- [GFQL Language Specification](https://docs.graphistry.com/gfql/spec/language/)\n",
    "- [Production Validation Patterns](./gfql_validation_production.ipynb)\n",
    "- [GFQL Documentation](https://docs.graphistry.com/gfql/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}