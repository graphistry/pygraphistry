{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c39da4a9",
   "metadata": {},
   "source": [
    "# Hello PyGraphistry[ai] - HackerNews visual semantic search with UMAP & BERT and \n",
    "\n",
    "`PyGraphistry[ai]` can quickly create visual graph search interfaces for structured text. It automates much of the work in cleaning, connecting, encoding, searching, and visualing graph data. The result is increasing the *time to graph* and overall results in as little as one line of code.\n",
    "\n",
    "This notebook shows how to turn 3,000 HackerNews articles into an interactive visual graph with full semantic search. The core flow is a short number of lines and trains in 2 minutes on a CPU and 100-200x faster on GPU. The notebooks carefully demonstrate how to create a fast automatic feature engineering pipeline, which exposes matrices and targets, a Scikits like API, full semantic search over the data which returns dataframes or subgraphs from the query, and `GNN` models and pipelines.\n",
    "\n",
    "Outline:\n",
    "\n",
    "* load the data into a graphistry instance, `g = graphistry.nodes(dataframe)`\n",
    "* since we do not have explicit edges, we will create a similarity graph using UMAP, `g.umap(..)` \n",
    "    which will call the `g.featurize(...)` api to create features, then UMAP them, adding an implicit edge dataframe which you can access with `g._edges` (with `g._nodes` the original dataframe) \n",
    "* Once the models are built we can search the data and display subgraphs from the search query itself\n",
    "    using `g.search(query)` and `g.search_graph(query).plot()`\n",
    "* Transforming on new data using `g.transform(..)`, useful for online or API driven endpoints after a data model has been set\n",
    "* lastly, create a DGL GNN data model `g.build_gnn(...)` which may be used for downstream `GNN` modeling\n",
    "\n",
    "Searching over data is useful to refine and find sugraphs over the global corpus of documents/events/data. Search can be operationalized over logs data (see morpheus demo), eCommerce (see clickstream and user-item-recommendation demo), stock and coin data (see crypto-slim demo), OSINT data, etc.\n",
    "\n",
    "`GNN`s built over these feature encodings are useful for downstream modeling like link prediction, node classification, motif mining and other popular graph AI pipelines. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385ea5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# depends on where you have your data/ folder\n",
    "#mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7f75b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install --upgrade graphistry[ai]   # get the latest graphistry AI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd6050e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd .. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503a96d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import graphistry\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73d67a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1/137\n",
    "np.random.seed(int(alpha**-1))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f3b61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your hub credentials here\n",
    "graphistry.register(api=3, protocol=\"https\", server=\"hub.graphistry.com\", username = os.environ['USERNAME'], password=os.environ['GRAPHISTRY_PASSWORD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0bcb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data top 3000 posts on Hacker News\n",
    "df = pd.read_csv('https://storage.googleapis.com/cohere-assets/blog/text-clustering/data/askhn3k_df.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a407dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_cols = ['title', 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8edc98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9536276e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()  # see the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a479ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[good_cols].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2778f68",
   "metadata": {},
   "source": [
    "# Featurize and Encode the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748116ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "t0 = time()\n",
    "################################################################\n",
    "## Two Lines of codes cuts through 80% of the datasciencing \n",
    "\n",
    "df = df.sample(3000) # set smaller if you want to test a minibatch \n",
    "\n",
    "################################################################\n",
    "# create the graphistry instance\n",
    "g = graphistry.nodes(df)\n",
    "\n",
    "# set to False if you want to reload last trained instance\n",
    "process = True\n",
    "\n",
    "if process:\n",
    "    # Umap will create a similarity graph from the features which we can view as a graph\n",
    "    g2 = g.umap(X=['title', 'text'], # the features to encode (can add/remove 'text', etc)\n",
    "                y=['score'], # for demonstrative purposes, we include a target -- though this one is not really conditioned on textual features in a straightforward way\n",
    "                model_name='msmarco-distilbert-base-v2', #'paraphrase-MiniLM-L6-v2', etc, from sbert/Huggingface, the text encoding model\n",
    "                min_words = 0, # when 0 forces all X=[..] as textually encoded, higher values would ascertain if a column is textual or not depending on average number of words per column\n",
    "                use_ngrams=False, # set to True if you want ngram features instead (does not make great plots but useful for other situations)\n",
    "                use_scaler_target='zscale', # for regressive targets\n",
    "                use_scaler=None, # there are many more settings see `g.featurize?` and `g.umap?` for further options\n",
    "               )\n",
    "    g2.save_search_instance('data/hn.search')\n",
    "    print('-'*80)\n",
    "    print(f'Encoding {df.shape[0]} records using {str(g2._node_encoder.text_model)[:19]} took {(time()-t0)/60:.2f} minutes')\n",
    "else:\n",
    "    # or load the search instance\n",
    "    g2 = g.load_search_instance('data/hn.search')\n",
    "    print('-'*80)\n",
    "    print(f'Loaded saved instance')\n",
    "    \n",
    "################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6de7795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see all the data\n",
    "g2.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ed4eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the encoded features, and use in downstream models (clf.fit(x, y), etc)\n",
    "x=g2._get_feature('nodes')\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b15408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# likewise with the (scaled) targets\n",
    "y = g2._get_target('nodes')\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43b7806",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# visualize the results where we prune edges using the `filter_weighted_edges` method\n",
    "# this keeps all weights that are (more similar) 0.5 and above. The initial layout is the same (given by umap in 2d)\n",
    "g25 = g2.filter_weighted_edges(0.5)\n",
    "g25.plot(render=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f547e2",
   "metadata": {},
   "source": [
    "# Let's query the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79eabfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# direct keyword search when fuzzy=False and a set of columns are given, does not require featurization\n",
    "g.search('love', fuzzy=False, cols=['title'])[0][['title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cf9c06",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Query semantically instead of strict keyword matching\n",
    "\n",
    "sample_queries = ['Is true love possible?', \n",
    "                  'How to create deep learning models?', \n",
    "                  'Best tech careers',\n",
    "                  'How do I make more money?', \n",
    "                  'Advances in particle physics', \n",
    "                  'Best apps and gadgets', \n",
    "                  'Graph Neural Networks', \n",
    "                  'recommend impactful books', \n",
    "                  'lamenting about life']\n",
    "\n",
    "for query in sample_queries:\n",
    "    print('*'*33)\n",
    "    print(query)\n",
    "    print('*'*30)\n",
    "    # use the featurized instance g2 for semantic search\n",
    "    results_df, encoded_query_vector = g2.search(query)\n",
    "    print(results_df['title'])\n",
    "    print('-'*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c07e601",
   "metadata": {},
   "source": [
    "# Search to Graph\n",
    "\n",
    "We may also query and create a graph of results. This returns the nodes found during `g.search` and then pulls in any edges of those nodes in both the `src` AND `dst` or, with `broader=True`, with nodes in `src` OR `dst` -- the latter can be useful in user-relationship-item/user/behavioral datasets and recommendation strategies where NLP search can help recall/create ontologically similar mini-batches to broaden scope. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302a0b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr = g2.search_graph('How to create deep learning models', thresh=15, top_n=50, scale=0.25, broader=False) \n",
    "gr.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543f7b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "g2.search_graph('Graph Neural Networks', thresh=50, top_n=50, scale=0.1, broader=False).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2f9157",
   "metadata": {},
   "outputs": [],
   "source": [
    "g2.search_graph('fraud detection algorithms', thresh=50, top_n=50, scale=0.1, broader=False).plot()  # works better if you encode 'text' column as well"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a5c146",
   "metadata": {},
   "source": [
    "# To Demonstrate transforming on new or unseen data (imagine a train test split or new mini batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b941fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = g2.transform(df.sample(10), df.sample(10), kind='nodes')  # or edges if given or already produced through umap-ing the nodes, \n",
    "                                                                #and if neither, set `embedding=True` for random embedding of size `n_topics`\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3638a486",
   "metadata": {},
   "source": [
    "Likewise, we can `transform_umap` to get the embedding coordinates as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68126cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb, x, y = g2.transform_umap(df.sample(10), df.sample(10))\n",
    "emb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f94749",
   "metadata": {},
   "source": [
    "# Build a GNN model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d148348e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this inherets all the arguments from the g.featurize api for both nodes and edges, see g.build_gnn? for details\n",
    "g3 = g25.build_gnn()  # we use the filtered edges graphistry instance as it has higher fidelity similarity scores on edges\n",
    "                        # ie, less edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5989c286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notice the difference in edge dataframes between g2/5 and g3\n",
    "g25._edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59af921c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# versus\n",
    "g3._edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1cd73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edges come from data supplied by umap on nodes\n",
    "g3._edge_encoder.feature_names_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764e7ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "g3._edge_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1955b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since edges are featurized, we can transform on \"unseen/batch\" ones\n",
    "# y_edges will be none since we don't have a label for the implicit edges. One could supply it via enrichment (like clustering, annotation etc)\n",
    "edge_data = g3._edges.sample(10)\n",
    "\n",
    "x_edges, _ = g3.transform(edge_data, None, kind='edges')\n",
    "x_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d403f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# once built, we can get the DGL graph itself\n",
    "G = g3.DGL_graph\n",
    "G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8380122a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the features, targets, and masks\n",
    "G.ndata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63beefab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# `build_gnn()` will turn edges gotten from umap into bonafide feature matrices, \n",
    "# and make features out of explicit edges with `build_gnn(X_edges=[...], ..)`\n",
    "G.edata['feature'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d3a37a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# see the edge features which are shape (n_edges, n_nodes + weight)\n",
    "# notice that had we used filter_weighted_edges to create a new graphistry instance and then .build_gnn() we would get\n",
    "# a different n_edges. Useful to keep in mind when building models without an explicit edge_dataframe\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.imshow(G.edata['feature'][:400, :600], aspect='auto', cmap='hot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c150a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see the way edges are related across the first 500 edges.\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.imshow(np.cov(G.edata['feature'][:500]), aspect='auto', cmap='hot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab619bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to see how to train a GNN, see the cyber or influence tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f170fa3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
