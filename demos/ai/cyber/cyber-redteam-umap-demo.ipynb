{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "beb5e3e3-f8cd-40ed-bc63-8a862000f192",
   "metadata": {},
   "source": [
    "# Analyzing Network Identity Data and Red Team Response with Graphistry AutoML + UMAP\n",
    "\n",
    "We find a simple model that when clustered in a 2d plane via UMAP allows fast identification of anomalous \n",
    "computer to computer connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9de6fd3-b87b-4dc4-8d1c-b8f3feceb5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install graphistry[ai] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0215906c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import graphistry\n",
    "\n",
    "import os\n",
    "from joblib import load, dump\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sknetwork.ranking import PageRank\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e1cc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "graphistry.register(api=3, protocol=\"https\", server=\"hub.graphistry.com\", username = os.environ['USERNAME'], password=os.environ['GRAPHISTRY_PASSWORD'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877b4e50-8fa8-4663-bba0-91b661fc735f",
   "metadata": {},
   "source": [
    "Alert on & visualize anomalous identity events\n",
    "\n",
    "Demo dataset: 1.6B windows events over 58 days => logins by 12K user over 14K systems\n",
    "adapt to any identity system with logins. Here we subsample down to a small set of 50k events to prove out the pipeline. \n",
    "\n",
    "* => Can we identify accounts & computers acting anomalously? Resources being oddly accessed?\n",
    "* => Can we spot the red team?\n",
    "* => Operations: Identity incident alerting + identity data investigations\n",
    "\n",
    "Community/contact for help handling bigger-than-memory & additional features\n",
    "\n",
    "Runs on both CPU + multi-GPU\n",
    "Tools: PyGraphistry[AI], DGL + PyTorch, and NVIDIA RAPIDS / umap-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6e61b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cite data source\n",
    "# \"\"\"A. D. Kent, \"Cybersecurity Data Sources for Dynamic Network Research,\"\n",
    "# in Dynamic Networks in Cybersecurity, 2015.\n",
    "\n",
    "# @InProceedings{akent-2015-enterprise-data,\n",
    "#    author = {Alexander D. Kent},\n",
    "#    title = {{Cybersecurity Data Sources for Dynamic Network Research}},\n",
    "#    year = 2015,\n",
    "#    booktitle = {Dynamic Networks in Cybersecurity},\n",
    "#    month =        jun,\n",
    "#    publisher = {Imperial College Press}\n",
    "# }\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554c0d85-1c8a-47f0-87ec-1629d7f7ba3b",
   "metadata": {},
   "source": [
    "# Data Loading and Munging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe68cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# small sample (get almost equivalent results without overheating computer over the 1.6B events in the full dataset)\n",
    "df = pd.read_csv('https://gist.githubusercontent.com/silkspace/c7b50d0c03dc59f63c48d68d696958ff/raw/31d918267f86f8252d42d2e9597ba6fc03fcdac2/redteam_50k.csv', index_col=0)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03610297",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape) # -> 50k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c5126e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here are the post-facto red team events\n",
    "red_team = pd.read_csv('https://gist.githubusercontent.com/silkspace/5cf5a94b9ac4b4ffe38904f20d93edb1/raw/888dabd86f88ea747cf9ff5f6c44725e21536465/redteam_labels.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6615aa",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "Make sure you `mkdir(data)` or change path below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3641d3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "process = True  \n",
    "# makes a combined feature we can use for topic modeling!\n",
    "if process:\n",
    "    # we create two types of models\n",
    "    df['feats'] = df.src_computer + ' ' + df.dst_computer + ' ' + df.auth_type + ' ' + df.logontype\n",
    "    # and one of just computer to computer \n",
    "    df['feats2'] = df.src_computer + ' ' + df.dst_computer\n",
    "    ndf = df.drop_duplicates(subset=['feats'])\n",
    "    ndf.to_parquet('../data/auth-50k-feats-one-column.parquet')\n",
    "else:\n",
    "    ndf = pd.read_parquet('../data/auth-50k-feats-one-column.parquet')\n",
    "    \n",
    "print(ndf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d1755d",
   "metadata": {},
   "source": [
    "## Red Team Data \n",
    "Add it to the front of the DataFrame so we can keep track of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67c86b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a subsampled dataframe with the anom red-team data at top...so we can keep track.\n",
    "# we don't need the full `df`, only the unique entries of 'feats' in `ndf` for \n",
    "# fitting a model (in a few cells below)\n",
    "\n",
    "tdf = pd.concat([red_team.reset_index(), ndf.reset_index()])\n",
    "tdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f62b7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a fidicial index used later\n",
    "tdf['node'] = range(len(tdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffd6aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total number of red team events\n",
    "tdf.RED.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4264d547-b4a9-49d1-bc68-894f1e839c38",
   "metadata": {},
   "source": [
    "## Enrichment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c53f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some enrichments\n",
    "def pagerank(g):\n",
    "    from sknetwork.ranking import PageRank\n",
    "    adj = g._weighted_adjacency\n",
    "    pagerank = PageRank()\n",
    "    ranks = pagerank.fit_transform(adj)\n",
    "    g._nodes['pagerank'] = ranks\n",
    "    return g\n",
    "\n",
    "def cluster(g):\n",
    "    \"\"\"\n",
    "        Fits clustering on UMAP embeddings\n",
    "    \"\"\"\n",
    "    dbscan = DBSCAN()\n",
    "    labels = dbscan.fit_predict(g._node_embedding)\n",
    "    g._nodes['cluster'] = labels\n",
    "    cnt = Counter(labels)\n",
    "    return g, dbscan, cnt\n",
    "\n",
    "def get_confidences_per_cluster(g, cnt):\n",
    "    \"\"\"\n",
    "        From DBSCAN clusters, will assess how many Red Team events exist,\n",
    "        assessing confidence.\n",
    "    \"\"\"\n",
    "    resses = []\n",
    "    df = g._nodes\n",
    "    for clust, count in cnt.most_common():\n",
    "        res = df[df.cluster==clust]\n",
    "        n = res.shape[0]\n",
    "        n_reds = res.RED.sum()\n",
    "        resses.append([clust, n_reds/n, n_reds, n])\n",
    "        if n_reds>0:\n",
    "            print('-'*20)\n",
    "            print(f'cluster: {clust}\\n   red {100*n_reds/n:.2f}% or {n_reds} out of {count}')\n",
    "    conf_dict = {k[0]:k[1] for k in resses}\n",
    "    confidence = [conf_dict[k] for k in df.cluster.values]\n",
    "    g._nodes['confidence'] = confidence\n",
    "    return g, pd.DataFrame(resses, columns=['cluster', 'confidence', 'n_red', 'total_in_cluster'])\n",
    "\n",
    "\n",
    "def enrich(g):\n",
    "    \"\"\"\n",
    "        Full Pipeline \n",
    "    \"\"\"\n",
    "    g = pagerank(g)\n",
    "    g, dbscan, cnt = cluster(g)\n",
    "    g, cluster_confidences = get_confidences_per_cluster(g, cnt)\n",
    "    return g, dbscan, cluster_confidences\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3da6e3-b280-4c69-b0e0-4a92d9aac231",
   "metadata": {},
   "source": [
    "# The Full UMAP Pipelines\n",
    "Fit a model on 'feats' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6909cc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "process = True  # set to false after it's run for ease of speed\n",
    "if process:\n",
    "    g = graphistry.nodes(tdf, 'node')\n",
    "    g5 = g.umap(X=['feats'], \n",
    "                min_words=1000000, # force high so that we don't use Sentence Transformers\n",
    "                cardinality_threshold=4, # set low so we force topic model\n",
    "                n_topics=32, # number of topics\n",
    "                use_scaler=None,\n",
    "                use_scaler_target=None\n",
    "               )\n",
    "    \n",
    "    g5, dbscan, cluster_confidences = enrich(g5)\n",
    "\n",
    "    g5.build_index()\n",
    "    g5.save_search_instance('../data/auth-feat-topic.search')\n",
    "else:\n",
    "    g = graphistry.bind()\n",
    "    g5 = g.load_search_instance('../data/auth-feat-topic.search')\n",
    "    g5, dbscan, cluster_confidences = enrich(g5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c13cba-bc36-4d49-8e7a-7dc05b27610a",
   "metadata": {},
   "source": [
    "## Plot it\n",
    "Color by `confidence` and hover over `red` team histogram to see where events occur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279fef41",
   "metadata": {},
   "outputs": [],
   "source": [
    "g5.name('auth 50k topic feats no target').plot(render=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ece955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see how the model has organized features\n",
    "X = g5._node_features\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632d6d0f-8212-4f4a-a920-7600d7456351",
   "metadata": {},
   "source": [
    "## Put model into Predict Mode\n",
    "\n",
    "Once a model is fit, can predict on new batches as we demonstrate here\n",
    "\n",
    "There are two main methods\n",
    "\n",
    "`g.transform` and `g.transform_umap` \n",
    "\n",
    "see help(*) on each to learn more\n",
    "\n",
    "One may save the model as above, load it, and wrap in a FastAPI endpoint, etc, to serve in production pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b44d418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first sample a batch from the normal data (auth=df)\n",
    "emb_normal, xp_normal, _ = g5.transform_umap(df.sample(200), None, kind='nodes')\n",
    "# then transform all the red team data\n",
    "emb_red, xp_red, _ = g5.transform_umap(red_team, None, kind='nodes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0aebbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all emb's have this form\n",
    "g5._node_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8d5aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter to see how well it does.\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.scatter(g5._node_embedding.x, g5._node_embedding.y , c='b')  # the totality of the fit data\n",
    "plt.scatter(emb_normal.x, emb_normal.y, c='g') # batch of new data\n",
    "plt.scatter(emb_red.x, emb_red.y, c='r') # red labels to show good cluster seperation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53dd8ed-39b2-4000-9ec7-139d1e2a6a85",
   "metadata": {},
   "source": [
    "## 96% Reduction in Alerts\n",
    "\n",
    "This indicates a huge reduction in the search space needed \n",
    "\n",
    "Since we have clear cluster assignments along with (post facto) confidences of known anomalous activity, we can reduce the search space on new events (via Kafka, Splunk, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d207db-9a58-45a3-9876-058632389f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# percent of RED team labels we get with 10% confidence or above\n",
    "p = cluster_confidences[cluster_confidences.confidence>0.1].n_red.sum()/cluster_confidences[cluster_confidences.confidence>0.1].total_in_cluster.sum()\n",
    "print(f'{100*p:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755a3f27-935d-4ba8-96cb-cbff11fdf00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of data points not to consider (and it's more if we look at df proper!)\n",
    "cluster_confidences[cluster_confidences.confidence<0.1].total_in_cluster.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd1cc50-0900-4694-8400-c426e314ec2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = cluster_confidences[cluster_confidences.confidence<0.1].total_in_cluster.sum()/cluster_confidences.total_in_cluster.sum()\n",
    "print(f'Alert Reduction {100*p:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee508a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(np.cumsum([k[2] for k in cluster_confidences.values]))\n",
    "plt.xlabel('Anomolous Cluster Number')  # shows that we can ignore first clusters (containing most of the alerts)\n",
    "plt.ylabel('Number of Identified Red Team Events')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f168ac8-2324-4f47-b0d7-e4a0b041624f",
   "metadata": {},
   "source": [
    "## Supervised UMAP\n",
    "Here we use the RED team label to help supervise the UMAP fit. \n",
    "This might be useful once teams have actually identified RED team events \n",
    "and want to help separate clusters. \n",
    "While separation is better, the unsupervised version does well without."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c6a16d-a899-43b6-a7ba-75b45f855a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "process = True\n",
    "if process:\n",
    "    g = graphistry.nodes(tdf, 'node')\n",
    "    g6 = g.umap(X=['feats'], y =['RED'], \n",
    "                min_words=100000, \n",
    "                cardinality_threshold=2, \n",
    "                n_topics=32,\n",
    "                use_scaler_target=None)\n",
    "    g6, dbscan6, cluster_confidences6  = enrich(g6)\n",
    "    g6.build_index()\n",
    "    g6.save_search_instance('../data/auth-feat-supervised-topic.search')\n",
    "else:\n",
    "    g = graphistry.bind()\n",
    "    g6 = g.load_search_instance('../data/auth-feat-supervised-topic.search')\n",
    "    g6, dbscan6, cluster_confidences6  = enrich(g6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc72ab4-c0da-4541-b32b-aa771d6e510f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Plot\n",
    "Color by `confidence` and hover over `red` team histogram to see where events occur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e09a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "g6.name('auth 50k topic with supervised umap').plot(render=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88169a53",
   "metadata": {},
   "source": [
    "## A model of Computer-Computer features only\n",
    "Here we ignore `auth_type` and `logontype` and just fit on computer to computer, unsupervised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099b9d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "process = True\n",
    "if process:\n",
    "    g = graphistry.nodes(tdf, 'node')\n",
    "    g7 = g.umap(X=['feats2'], #y =['RED'], \n",
    "                min_words=100000, \n",
    "                cardinality_threshold=2, \n",
    "                n_topics=32,\n",
    "                use_scaler_target=None)\n",
    "    g7, dbscan7, cluster_confidences7  = enrich(g7)\n",
    "    g7.build_index()\n",
    "    g7.save_search_instance('../data/auth-feat-just-ip-topic.search')\n",
    "else:\n",
    "    g7 = graphistry.bind().load_search_instance('../data/auth-feat-just-ip-topic.search')\n",
    "    g7, dbscan7, cluster_confidences7  = enrich(g7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836883cb-bc66-4a40-9ca8-f01fd38b6f2a",
   "metadata": {},
   "source": [
    "### Plot\n",
    "Color by `confidence` and hover over `red` team histogram to see where events occur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e586a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "g7.name('auth 50k topic only ips no supervision').plot(render=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f93d747",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = g7._get_feature('nodes')\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf68ed4",
   "metadata": {},
   "source": [
    "# Conditional Probability\n",
    "Let's see if  can give us good histograms to tease out red team nodes? This is to baseline the above UMAP models, and we find in retrospect, UMAP wins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6f58dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = graphistry.edges(tdf, \"src_computer\", \"dst_computer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b83f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditional_probability(x, given, df):\n",
    "    \"\"\"conditional probability function over categorical variables\n",
    "       p(x|given) = p(x,given)/p(given)\n",
    "        \n",
    "    Args:\n",
    "        x: the column variable of interest given the column 'given'\n",
    "        given: the variabe to fix constant\n",
    "        df: dataframe with columns [given, x]\n",
    "    Returns:\n",
    "        pd.DataFrame: the conditional probability of x given the column 'given'\n",
    "    \"\"\"\n",
    "    return df.groupby([given])[x].apply(lambda g: g.value_counts()/len(g))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd738336",
   "metadata": {},
   "outputs": [],
   "source": [
    "x='dst_computer'\n",
    "given='src_computer'\n",
    "condprobs = conditional_probability(x, given, df=tdf)\n",
    "\n",
    "cprob = pd.DataFrame(list(condprobs.index), columns=[given, x])\n",
    "cprob['_probs'] = condprobs.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5258aee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now enrich the edges dataframe with the redteam data\n",
    "# since cprobs lost those labels during the function cal\n",
    "indx = cprob.src_computer.isin(red_team.src_computer) & cprob.dst_computer.isin(red_team.dst_computer)\n",
    "cprob.loc[indx, 'red'] = 1\n",
    "cprob.loc[~indx, 'red'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3af1cd-6423-4484-8b99-81fad821f118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full condprob graph \n",
    "cg = graphistry.edges(cprob, x, given).bind(edge_weight='_probs')\n",
    "cg.plot(render=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fb3dff",
   "metadata": {},
   "source": [
    "## Learning\n",
    "The conditional graph shows that most of the edge probabilities are between 4e-7 and 0.03, whose bucket contains most events. Thus the chances of finding the red team edges are ~ 1e-4 -- slim indeed. UMAP wins."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2cd536",
   "metadata": {},
   "source": [
    "Likewise the transpose conditional is even worse \n",
    "with prob_detection ~ 6e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18eafcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's repeat but with reverse conditional\n",
    "x='src_computer'\n",
    "given='dst_computer'\n",
    "condprobs2 = conditional_probability(x, given, df=tdf)\n",
    "\n",
    "cprob2 = pd.DataFrame(list(condprobs2.index), columns=[given, x])\n",
    "cprob2['_probs'] = condprobs2.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74913e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now enrich the edges dataframe with the redteam data\n",
    "indx = cprob2.src_computer.isin(red_team.src_computer) & cprob2.dst_computer.isin(red_team.dst_computer)\n",
    "cprob2.loc[indx, 'red'] = 1\n",
    "cprob2.loc[~indx, 'red'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f4ac54",
   "metadata": {},
   "outputs": [],
   "source": [
    "cg2 = graphistry.edges(cprob2, x, given).bind(edge_weight='_probs')\n",
    "cg2.plot(render=False)\n",
    "# same conclusion as above..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db832e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # let's see the probs better:\n",
    "# for src in red_team.src_computer.unique():\n",
    "#     for dst in red_team.dst_computer.unique():\n",
    "#         if dst in condprobs[src]:\n",
    "#             print('-'*30)\n",
    "#             print(f'given src {src} -> dst {dst}')\n",
    "#             print('-'*10)\n",
    "#             print(f'   {condprobs[src][dst]*100:.2f}%')\n",
    "#             print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f51de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dst in red_team.dst_computer.unique():\n",
    "#     for src in red_team.src_computer.unique():\n",
    "#         if src in condprobs2[dst]:\n",
    "#             print('-'*20)\n",
    "#             print(f'given dst {dst} -> src {src}')\n",
    "#             print('-'*10)\n",
    "#             print(f'  {condprobs2[dst][src]*100:.2f}%')\n",
    "#             print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a008f6-75ed-4045-b13c-494cb015d185",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
